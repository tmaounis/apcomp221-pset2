{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup on Row 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clean the File\n",
    "2. Handle Corrupt Rows\n",
    "3. Explore Data Set Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Display Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(df, nrows=10, ncols=None):\n",
    "    with pd.option_context('display.max_rows', nrows, 'display.max_columns', ncols):\n",
    "        display (df)\n",
    "def print_row(df, row):\n",
    "    for ctr,i in enumerate(df.iloc[row]):\n",
    "        print (str(df.columns[ctr])+\": \"+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets ratio of NaNs for each column\n",
    "def stats_NaN(df):\n",
    "    df_stats = pd.DataFrame(index=[df.columns], columns=[\"NaN Ratio\"])\n",
    "    for col in df.columns:\n",
    "        df_stats[\"NaN Ratio\"][col] = df[col].isna().sum()/len(df) #NaN ratio\n",
    "    return df_stats.sort_values(by=['NaN Ratio'])\n",
    "\n",
    "#helps see what fields may be incorrect by having more values than should be\n",
    "def stats_unique(df, labels):\n",
    "    df_counts = pd.DataFrame(index=labels,columns=['Unique Count'])\n",
    "    for l in labels:\n",
    "        df_counts['Unique Count'][l] = df[l].nunique()\n",
    "    return df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 48 fields in line 652242, saw 49\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-88f3ed65eba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../dirty_sample_small.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 48 fields in line 652242, saw 49\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../dirty_sample_small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows have an extra field. We shall investigate what this is. First we will import the file in a more managable way, capable of handling these erroneous lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame([line.strip().split(',') for line in open('../dirty_sample_small.csv', \n",
    "                                                                'r', encoding=\"ISO-8859-1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661487"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Corrupt Lines and Discussing Duplicates (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One notion of corrupt lines is the lines in the raw dataset that are formatted improperly. These lines have made it difficult to import the file, though we have worked around it with the above code. These corrupt lines have to do with cleaning the dataset so will be discussed here. Interestingly, we will check some statistics on these lines with regards to duplicate entires. There is another notion of corrupt lines, dealing with the incorrectness and contradictoriness of datapoints, that we will investigate later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000270602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000498876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000757384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00102496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00126231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00155407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00181712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00207563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00235379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00264404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00291767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00316257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00343166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00372192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00397589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00421928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00446116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.00468339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.00495399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.00520948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.00549066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00576882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.00600616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.00624804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.00652016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.00674238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.00698426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.00722463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.00749977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.00774618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.00801225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.00826471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.00856706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.00882406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.00909617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.00936526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.00962075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00989891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.986152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NaN Ratio\n",
       "0             0\n",
       "1             0\n",
       "2             0\n",
       "3   0.000270602\n",
       "4   0.000498876\n",
       "5   0.000757384\n",
       "6    0.00102496\n",
       "7    0.00126231\n",
       "8    0.00155407\n",
       "9    0.00181712\n",
       "10   0.00207563\n",
       "11   0.00235379\n",
       "12   0.00264404\n",
       "13   0.00291767\n",
       "14   0.00316257\n",
       "15   0.00343166\n",
       "16   0.00372192\n",
       "17   0.00397589\n",
       "18   0.00421928\n",
       "19   0.00446116\n",
       "20   0.00468339\n",
       "21   0.00495399\n",
       "22   0.00520948\n",
       "23   0.00549066\n",
       "24   0.00576882\n",
       "25   0.00600616\n",
       "26   0.00624804\n",
       "27   0.00652016\n",
       "28   0.00674238\n",
       "29   0.00698426\n",
       "30   0.00722463\n",
       "31   0.00749977\n",
       "32   0.00774618\n",
       "33   0.00801225\n",
       "34   0.00826471\n",
       "35   0.00856706\n",
       "36   0.00882406\n",
       "37   0.00909617\n",
       "38   0.00936526\n",
       "39   0.00962075\n",
       "40   0.00989891\n",
       "41   0.00989891\n",
       "42   0.00989891\n",
       "43   0.00989891\n",
       "44   0.00989891\n",
       "45   0.00989891\n",
       "46   0.00989891\n",
       "47   0.00989891\n",
       "48     0.986152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_NaN(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that that the extra has 98.6% field NaNs. This is enough to drop it. However we want to do our due diligence and investigate what the values that are not NaN are. Our suspicion is that it contains the empty string \"\". So we will query this dataset on the extra field for values that are not NaN or not the empty string. These rows with the empty string are likely corrupt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: 48, dtype: object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[(pd.notna(df_raw[48]) & (df_raw[48] != ''))][48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this returns nothing. Therefore everything in the extra field is either NaN or the empty string, so there is absolutely no value in keeping it and we will drop it. But first, lets see how many of these corrupt erroneous lines there are. We know that the construction of df_raw line by line as we did above is indifferent to the amount of columns in each row. Most of the time it saw 48 columns, in the later rows it saw 49 because of the extra empty string. The construction of the data set put NaNs in the earlier rows to ensure the shape of the dataset is intact (a regular rectangle). Therefore the source of the corrupt lines is the empty string, so if we count the empty strings in the extra field we will have successfully counted the amount of corrupt lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9160"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw[((df_raw[48] == ''))][48])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 9160 of these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652241</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1818882</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>173.76.227.129</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>02458</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.3533</td>\n",
       "      <td>-71.1883</td>\n",
       "      <td>el</td>\n",
       "      <td>2002</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-12-04 04:02:20</td>\n",
       "      <td>2013-12-04 04:02:20.199004</td>\n",
       "      <td>2014-04-01 23:30:47.988143</td>\n",
       "      <td>2194</td>\n",
       "      <td>39</td>\n",
       "      <td>680</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 16:36:03</td>\n",
       "      <td>2014-09-15 17:57:23</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652242</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1818882</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>173.76.227.129</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>02458</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.3533</td>\n",
       "      <td>-71.1883</td>\n",
       "      <td>el</td>\n",
       "      <td>2002</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-12-04 04:02:20</td>\n",
       "      <td>2013-12-04 04:02:20.199004</td>\n",
       "      <td>2014-04-01 23:30:47.988143</td>\n",
       "      <td>2194</td>\n",
       "      <td>39</td>\n",
       "      <td>680</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 16:36:03</td>\n",
       "      <td>2014-09-15 17:57:23</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652243</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1818882</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>173.76.227.129</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>02458</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.3533</td>\n",
       "      <td>-71.1883</td>\n",
       "      <td>el</td>\n",
       "      <td>2002</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-12-04 04:02:20</td>\n",
       "      <td>2013-12-04 04:02:20.199004</td>\n",
       "      <td>2014-04-01 23:30:47.988143</td>\n",
       "      <td>2194</td>\n",
       "      <td>39</td>\n",
       "      <td>680</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 16:36:03</td>\n",
       "      <td>2014-09-15 17:57:23</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652244</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1818882</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>173.76.227.129</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>02458</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.3533</td>\n",
       "      <td>-71.1883</td>\n",
       "      <td>el</td>\n",
       "      <td>2002</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-12-04 04:02:20</td>\n",
       "      <td>2013-12-04 04:02:20.199004</td>\n",
       "      <td>2014-04-01 23:30:47.988143</td>\n",
       "      <td>2194</td>\n",
       "      <td>39</td>\n",
       "      <td>680</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 16:36:03</td>\n",
       "      <td>2014-09-15 17:57:23</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652245</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1818882</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>173.76.227.129</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>02458</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>42.3533</td>\n",
       "      <td>-71.1883</td>\n",
       "      <td>el</td>\n",
       "      <td>2002</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-12-04 04:02:20</td>\n",
       "      <td>2013-12-04 04:02:20.199004</td>\n",
       "      <td>2014-04-01 23:30:47.988143</td>\n",
       "      <td>2194</td>\n",
       "      <td>39</td>\n",
       "      <td>680</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 16:36:03</td>\n",
       "      <td>2014-09-15 17:57:23</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661482</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1934738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>71.41.229.179</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>75201</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32.7831</td>\n",
       "      <td>-96.8067</td>\n",
       "      <td>p</td>\n",
       "      <td>1972</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-07-09 01:46:41</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 15:08:24</td>\n",
       "      <td>2014-09-15 16:35:38</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661483</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1934738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>71.41.229.179</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>75201</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32.7831</td>\n",
       "      <td>-96.8067</td>\n",
       "      <td>p</td>\n",
       "      <td>1972</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-07-09 01:46:41</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 15:08:24</td>\n",
       "      <td>2014-09-15 16:35:38</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661484</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1934738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>71.41.229.179</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>75201</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32.7831</td>\n",
       "      <td>-96.8067</td>\n",
       "      <td>p</td>\n",
       "      <td>1972</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-07-09 01:46:41</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 15:08:24</td>\n",
       "      <td>2014-09-15 16:35:38</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661485</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1934738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>71.41.229.179</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>75201</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32.7831</td>\n",
       "      <td>-96.8067</td>\n",
       "      <td>p</td>\n",
       "      <td>1972</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-07-09 01:46:41</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 15:08:24</td>\n",
       "      <td>2014-09-15 16:35:38</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661486</th>\n",
       "      <td>HarvardX/CS50x/2014_T1</td>\n",
       "      <td>1934738</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>71.41.229.179</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Texas</td>\n",
       "      <td>75201</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>Developed regions</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32.7831</td>\n",
       "      <td>-96.8067</td>\n",
       "      <td>p</td>\n",
       "      <td>1972</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2013-07-09 01:46:41</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Student</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>honor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-06 15:08:24</td>\n",
       "      <td>2014-09-15 16:35:38</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9160 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0        1     2      3     4      5      6   \\\n",
       "652241  HarvardX/CS50x/2014_T1  1818882  True   True  True  False  False   \n",
       "652242  HarvardX/CS50x/2014_T1  1818882  True   True  True  False  False   \n",
       "652243  HarvardX/CS50x/2014_T1  1818882  True   True  True  False  False   \n",
       "652244  HarvardX/CS50x/2014_T1  1818882  True   True  True  False  False   \n",
       "652245  HarvardX/CS50x/2014_T1  1818882  True   True  True  False  False   \n",
       "...                        ...      ...   ...    ...   ...    ...    ...   \n",
       "661482  HarvardX/CS50x/2014_T1  1934738  True  False        False  False   \n",
       "661483  HarvardX/CS50x/2014_T1  1934738  True  False        False  False   \n",
       "661484  HarvardX/CS50x/2014_T1  1934738  True  False        False  False   \n",
       "661485  HarvardX/CS50x/2014_T1  1934738  True  False        False  False   \n",
       "661486  HarvardX/CS50x/2014_T1  1934738  True  False        False  False   \n",
       "\n",
       "                    7   8              9         10      11  12  \\\n",
       "652241  173.76.227.129  US  United States  Americas  Newton  MA   \n",
       "652242  173.76.227.129  US  United States  Americas  Newton  MA   \n",
       "652243  173.76.227.129  US  United States  Americas  Newton  MA   \n",
       "652244  173.76.227.129  US  United States  Americas  Newton  MA   \n",
       "652245  173.76.227.129  US  United States  Americas  Newton  MA   \n",
       "...                ...  ..            ...       ...     ...  ..   \n",
       "661482   71.41.229.179  US  United States  Americas  Dallas  TX   \n",
       "661483   71.41.229.179  US  United States  Americas  Dallas  TX   \n",
       "661484   71.41.229.179  US  United States  Americas  Dallas  TX   \n",
       "661485   71.41.229.179  US  United States  Americas  Dallas  TX   \n",
       "661486   71.41.229.179  US  United States  Americas  Dallas  TX   \n",
       "\n",
       "                   13     14                15                 16 17 18  \\\n",
       "652241  Massachusetts  02458  Northern America  Developed regions         \n",
       "652242  Massachusetts  02458  Northern America  Developed regions         \n",
       "652243  Massachusetts  02458  Northern America  Developed regions         \n",
       "652244  Massachusetts  02458  Northern America  Developed regions         \n",
       "652245  Massachusetts  02458  Northern America  Developed regions         \n",
       "...               ...    ...               ...                ... .. ..   \n",
       "661482          Texas  75201  Northern America  Developed regions         \n",
       "661483          Texas  75201  Northern America  Developed regions         \n",
       "661484          Texas  75201  Northern America  Developed regions         \n",
       "661485          Texas  75201  Northern America  Developed regions         \n",
       "661486          Texas  75201  Northern America  Developed regions         \n",
       "\n",
       "             19        20  21    22 23   24   25                   26  \\\n",
       "652241  42.3533  -71.1883  el  2002  m  0.0  0.6  2013-12-04 04:02:20   \n",
       "652242  42.3533  -71.1883  el  2002  m  0.0  0.6  2013-12-04 04:02:20   \n",
       "652243  42.3533  -71.1883  el  2002  m  0.0  0.6  2013-12-04 04:02:20   \n",
       "652244  42.3533  -71.1883  el  2002  m  0.0  0.6  2013-12-04 04:02:20   \n",
       "652245  42.3533  -71.1883  el  2002  m  0.0  0.6  2013-12-04 04:02:20   \n",
       "...         ...       ...  ..   ... ..  ...  ...                  ...   \n",
       "661482  32.7831  -96.8067   p  1972  m  0.0  0.6  2013-07-09 01:46:41   \n",
       "661483  32.7831  -96.8067   p  1972  m  0.0  0.6  2013-07-09 01:46:41   \n",
       "661484  32.7831  -96.8067   p  1972  m  0.0  0.6  2013-07-09 01:46:41   \n",
       "661485  32.7831  -96.8067   p  1972  m  0.0  0.6  2013-07-09 01:46:41   \n",
       "661486  32.7831  -96.8067   p  1972  m  0.0  0.6  2013-07-09 01:46:41   \n",
       "\n",
       "                                27                          28    29  30   31  \\\n",
       "652241  2013-12-04 04:02:20.199004  2014-04-01 23:30:47.988143  2194  39  680   \n",
       "652242  2013-12-04 04:02:20.199004  2014-04-01 23:30:47.988143  2194  39  680   \n",
       "652243  2013-12-04 04:02:20.199004  2014-04-01 23:30:47.988143  2194  39  680   \n",
       "652244  2013-12-04 04:02:20.199004  2014-04-01 23:30:47.988143  2194  39  680   \n",
       "652245  2013-12-04 04:02:20.199004  2014-04-01 23:30:47.988143  2194  39  680   \n",
       "...                            ...                         ...   ...  ..  ...   \n",
       "661482                                                                          \n",
       "661483                                                                          \n",
       "661484                                                                          \n",
       "661485                                                                          \n",
       "661486                                                                          \n",
       "\n",
       "       32 33 34 35 36 37 38       39 40 41 42     43 44                   45  \\\n",
       "652241  8                    Student  0  0  0  honor  1  2014-06-06 16:36:03   \n",
       "652242  8                    Student  0  0  0  honor  1  2014-06-06 16:36:03   \n",
       "652243  8                    Student  0  0  0  honor  1  2014-06-06 16:36:03   \n",
       "652244  8                    Student  0  0  0  honor  1  2014-06-06 16:36:03   \n",
       "652245  8                    Student  0  0  0  honor  1  2014-06-06 16:36:03   \n",
       "...    .. .. .. .. .. .. ..      ... .. .. ..    ... ..                  ...   \n",
       "661482                       Student           honor  1  2014-06-06 15:08:24   \n",
       "661483                       Student           honor  1  2014-06-06 15:08:24   \n",
       "661484                       Student           honor  1  2014-06-06 15:08:24   \n",
       "661485                       Student           honor  1  2014-06-06 15:08:24   \n",
       "661486                       Student           honor  1  2014-06-06 15:08:24   \n",
       "\n",
       "                         46          47 48  \n",
       "652241  2014-09-15 17:57:23  notpassing     \n",
       "652242  2014-09-15 17:57:23  notpassing     \n",
       "652243  2014-09-15 17:57:23  notpassing     \n",
       "652244  2014-09-15 17:57:23  notpassing     \n",
       "652245  2014-09-15 17:57:23  notpassing     \n",
       "...                     ...         ... ..  \n",
       "661482  2014-09-15 16:35:38  notpassing     \n",
       "661483  2014-09-15 16:35:38  notpassing     \n",
       "661484  2014-09-15 16:35:38  notpassing     \n",
       "661485  2014-09-15 16:35:38  notpassing     \n",
       "661486  2014-09-15 16:35:38  notpassing     \n",
       "\n",
       "[9160 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df(df_raw[((df_raw[48] == ''))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these \"corrupt\" lines contains valid data, so we will have to handle them. It does appear though that many of these 9160 corrupt lines are indeed duplicates. Lets see how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw[((df_raw[48] == ''))].drop_duplicates(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw[((df_raw[48] == ''))].drop_duplicates(subset=[0,1],\n",
    "                                                 inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So of the 9160 corrupt lines, at least 9160 - 710 = 8450 are duplicates. I say at least because even those 710 lines may be duplicates with the rest of the raw dataset as this analysis above only considers rows with the empty string in the extra field. So we can analyze overall the amount of duplicates in the whole raw dataset and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57223"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw.drop_duplicates(inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, there are still many more duplicates. However, if we had dropped duplicates at this stage, then we would have also gotten rid of at least 8450 corrupt lines. Therefore we posit, that dropping duplicates would drastically change the count of corrupt lines. We shall prove this with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_raw.drop_duplicates(inplace=False)[df_raw[48] == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that that these corrupt lines do have 710 valid samples. Therefore simply dropping duplicates in the whole dataset is guarunteed to drop 8450 of the corrupt lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Shifted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that some of the data appears scrambled. Meaning some of the data for some columns is in the wrong columns. We elucidate below. But first, lets give our dataset acceptable column names and drop the erroneous column. From now on, we will be using the goal dataset (the future fully cleaned one) called `df_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_raw.copy()\n",
    "df_clean = df_clean.rename(columns=df_raw.iloc[0])\n",
    "df_clean = df_clean.drop(df_clean.index[0])\n",
    "df_clean = df_clean.drop(np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>49144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explored</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certified</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed</th>\n",
       "      <td>44101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_by_ip</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countryLabel</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent</th>\n",
       "      <td>6509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdivision</th>\n",
       "      <td>9055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postalCode</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_major_region</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_economic_group</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_developing_nation</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_special_region</th>\n",
       "      <td>9821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>10569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoE</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YoB</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passing_grade</th>\n",
       "      <td>47896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>33443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_event</th>\n",
       "      <td>40371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_event</th>\n",
       "      <td>3238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nevents</th>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndays_act</th>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nplay_video</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nchapters</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_posts</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_votes</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_endorsed</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_threads</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_comments</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_pinned</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roles</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nprogcheck</th>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nproblem_check</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_events</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_active</th>\n",
       "      <td>22286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert_created_date</th>\n",
       "      <td>21901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert_modified_date</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert_status</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unique Count\n",
       "course_id                      21\n",
       "user_id                     49144\n",
       "registered                      3\n",
       "viewed                          3\n",
       "explored                        3\n",
       "certified                       2\n",
       "completed                   44101\n",
       "ip                            799\n",
       "cc_by_ip                      295\n",
       "countryLabel                   96\n",
       "continent                    6509\n",
       "city                         1145\n",
       "region                       1646\n",
       "subdivision                  9055\n",
       "postalCode                    282\n",
       "un_major_region                21\n",
       "un_economic_group               4\n",
       "un_developing_nation            4\n",
       "un_special_region            9821\n",
       "latitude                    10569\n",
       "longitude                     443\n",
       "LoE                           115\n",
       "YoB                            59\n",
       "gender                        105\n",
       "grade                           8\n",
       "passing_grade               47896\n",
       "start_time                  33443\n",
       "first_event                 40371\n",
       "last_event                   3238\n",
       "nevents                       267\n",
       "ndays_act                     873\n",
       "nplay_video                   111\n",
       "nchapters                      68\n",
       "nforum_posts                   43\n",
       "nforum_votes                    6\n",
       "nforum_endorsed                33\n",
       "nforum_threads                 66\n",
       "nforum_comments                 5\n",
       "nforum_pinned                   3\n",
       "roles                         107\n",
       "nprogcheck                    578\n",
       "nproblem_check                213\n",
       "nforum_events                   5\n",
       "mode                            6\n",
       "is_active                   22286\n",
       "cert_created_date           21901\n",
       "cert_modified_date            608\n",
       "cert_status                   607"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_unique(df_clean, df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>course_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewed</th>\n",
       "      <td>0.000270603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explored</th>\n",
       "      <td>0.000498877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certified</th>\n",
       "      <td>0.000757386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed</th>\n",
       "      <td>0.00102497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip</th>\n",
       "      <td>0.00126231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_by_ip</th>\n",
       "      <td>0.00155408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countryLabel</th>\n",
       "      <td>0.00181712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent</th>\n",
       "      <td>0.00207563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0.00235379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>0.00264405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdivision</th>\n",
       "      <td>0.00291767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postalCode</th>\n",
       "      <td>0.00316258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_major_region</th>\n",
       "      <td>0.00343167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_economic_group</th>\n",
       "      <td>0.00372192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_developing_nation</th>\n",
       "      <td>0.0039759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>un_special_region</th>\n",
       "      <td>0.00421929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.00446117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.00468339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoE</th>\n",
       "      <td>0.004954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YoB</th>\n",
       "      <td>0.00520948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.00549067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0.00576883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passing_grade</th>\n",
       "      <td>0.00600617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>0.00624805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_event</th>\n",
       "      <td>0.00652017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_event</th>\n",
       "      <td>0.0067424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nevents</th>\n",
       "      <td>0.00698427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndays_act</th>\n",
       "      <td>0.00722464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nplay_video</th>\n",
       "      <td>0.00749978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nchapters</th>\n",
       "      <td>0.0077462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_posts</th>\n",
       "      <td>0.00801226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_votes</th>\n",
       "      <td>0.00826473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_endorsed</th>\n",
       "      <td>0.00856707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_threads</th>\n",
       "      <td>0.00882407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_comments</th>\n",
       "      <td>0.00909619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_pinned</th>\n",
       "      <td>0.00936528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roles</th>\n",
       "      <td>0.00962076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nprogcheck</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nproblem_check</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_events</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_active</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert_created_date</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert_modified_date</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert_status</th>\n",
       "      <td>0.00989892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NaN Ratio\n",
       "course_id                       0\n",
       "user_id                         0\n",
       "registered                      0\n",
       "viewed                0.000270603\n",
       "explored              0.000498877\n",
       "certified             0.000757386\n",
       "completed              0.00102497\n",
       "ip                     0.00126231\n",
       "cc_by_ip               0.00155408\n",
       "countryLabel           0.00181712\n",
       "continent              0.00207563\n",
       "city                   0.00235379\n",
       "region                 0.00264405\n",
       "subdivision            0.00291767\n",
       "postalCode             0.00316258\n",
       "un_major_region        0.00343167\n",
       "un_economic_group      0.00372192\n",
       "un_developing_nation    0.0039759\n",
       "un_special_region      0.00421929\n",
       "latitude               0.00446117\n",
       "longitude              0.00468339\n",
       "LoE                      0.004954\n",
       "YoB                    0.00520948\n",
       "gender                 0.00549067\n",
       "grade                  0.00576883\n",
       "passing_grade          0.00600617\n",
       "start_time             0.00624805\n",
       "first_event            0.00652017\n",
       "last_event              0.0067424\n",
       "nevents                0.00698427\n",
       "ndays_act              0.00722464\n",
       "nplay_video            0.00749978\n",
       "nchapters               0.0077462\n",
       "nforum_posts           0.00801226\n",
       "nforum_votes           0.00826473\n",
       "nforum_endorsed        0.00856707\n",
       "nforum_threads         0.00882407\n",
       "nforum_comments        0.00909619\n",
       "nforum_pinned          0.00936528\n",
       "roles                  0.00962076\n",
       "nprogcheck             0.00989892\n",
       "nproblem_check         0.00989892\n",
       "nforum_events          0.00989892\n",
       "mode                   0.00989892\n",
       "is_active              0.00989892\n",
       "cert_created_date      0.00989892\n",
       "cert_modified_date     0.00989892\n",
       "cert_status            0.00989892"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_NaN(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first perceivable error in the dataset occurs under the completed field. It often has the IP in it. Therefore, one of the early fields is the source of the problem. Perhaps one field is missing. However we are finding it difficult to determine which one. Sometimes, `viewed` is empty, sometimes `explored` is. Often we see `registered` equal to False, which also makes no sense as in order to be a row in the dataset that user needs to be registered for the course. Initially we are thinking that whenever `registered` is False, that it should really be True and that is the source of the missing field and therefore the cause of the shift. However, we cant be certain. Sometimes `registered` is indeed True. `completed` is an important field for researchers of the edX dataset, so we most definitely must repair this column, and we can likely assume that one of the previous columns, probably `certified` contains the values for that column. But which column is missing? The four fields previous `completed` are all booleans, so it is difficult to identify where the problem originates. We know for sure that if the `ip` is in the completed column we can shift the datapoints starting in `completed` over to the right one. We have decided that the source of the shift is the `registered` column. It is the least important for researchers as it is redundant and should always be True. Therefore we start the shift over from there and fill the value with True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We target the `completed` column for values that look like IP addresses. In this case, we are looking for values that would not be the acceptable values in the `completed` column. The `completed` column should have either True, False, or perhaps None or empty string - anything that is not these is likely an IP address. **We discovered later that the empty string is a source of a shift and remedied that.** We then shift everything beginning at `registered` over as that is a reasonable assumption as to what the missing column is and we will then fill that column with Trues as everyone in the database is registered for the class. We do recognize that any of the other boolean fields could have been the source of the shift like `viewed`, `explored`, `certified`, or even `completed` (though we think this is less likely given these fields seem more important for analysis). A cursory glance at the data shows that `explored` is often empty - could this be the source of the problem? We think not, as we remember many NaN values in the `explored` column in the previous pset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets rows that look like the IP or the empty string is in the completed field \n",
    "#and shifts them\n",
    "df_shift = df_clean[~df_clean['completed'].isin(['True','False', None])]\\\n",
    "[df_clean.columns[2:]].shift(1, axis=1)\n",
    "df_shift.registered = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[~df_clean['completed'].isin(['True','False', None]),\\\n",
    "            df_clean.columns[2:]] = df_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>registered</th>\n",
       "      <th>viewed</th>\n",
       "      <th>explored</th>\n",
       "      <th>certified</th>\n",
       "      <th>completed</th>\n",
       "      <th>ip</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>countryLabel</th>\n",
       "      <th>...</th>\n",
       "      <th>nforum_pinned</th>\n",
       "      <th>roles</th>\n",
       "      <th>nprogcheck</th>\n",
       "      <th>nproblem_check</th>\n",
       "      <th>nforum_events</th>\n",
       "      <th>mode</th>\n",
       "      <th>is_active</th>\n",
       "      <th>cert_created_date</th>\n",
       "      <th>cert_modified_date</th>\n",
       "      <th>cert_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652240</th>\n",
       "      <td>6:36:03</td>\n",
       "      <td>2014-09-15 17:57:23</td>\n",
       "      <td>notpassing</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       course_id              user_id  registered viewed explored certified  \\\n",
       "652240   6:36:03  2014-09-15 17:57:23  notpassing            None      None   \n",
       "\n",
       "       completed    ip cc_by_ip countryLabel     ...     nforum_pinned roles  \\\n",
       "652240      None  None     None         None     ...              None  None   \n",
       "\n",
       "       nprogcheck nproblem_check nforum_events  mode is_active  \\\n",
       "652240       None           None          None  None      None   \n",
       "\n",
       "       cert_created_date cert_modified_date cert_status  \n",
       "652240              None               None        None  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[df_clean['user_id']=='2014-09-15 17:57:23']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This row is identified in our `fix_types` function as a shift, but it is complete garbage, so we will just drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop(652240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully fixed the shifting in the dataset! Our function below proves it as it does not identify any shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Data Types and Handling Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fixed the shifting, it will be more efficient to fix the datatypes. They are incorrect in multiple ways. For example, things that say False are not really the boolean value for false, but rather the string. In fact everything is a string. We will correct this in a systematic way. We will try to best follow the guidelines outlined here: https://elitedatascience.com/data-cleaning. We will have 2 functions. One for handling the fields that are supposed to be strings and the other for the other types. `fix_types_strings` will be like pandas replace function and deal with finding the empty strings. The other function `fix_types` will take a dictionary of column names to datatypes and run through the columns correcting the datatypes. Columns not specified in the dictionary will be left as strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary for chaning the non-string types is below. Most of these type conversions are self explanatory. But some of these choices in type conversions and in conversions I dont make require explanation. I am leaving `postalCode` as a string: this is because not all postal codes are numbers, some contain letters like in Great Britain. For `latitude` and `longitude` a float is enough space to hold their values, a double is not necessary. Many of the fields require datetime format which will be handled in the `fix_types` function. Lastly, `is_active` is described as an integer 1 or 0 in the documentation (and not a boolean) so we will treat it as such. The dictionary is equipped with the default value in the case that a datapoint is missing. Our `fix_types` function will utilize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_int = 0\n",
    "missing_float = 0\n",
    "missing_bool = False\n",
    "missing_datetime = datetime.min\n",
    "type_dict = {\n",
    "    'user_id' : (int, missing_int),\n",
    "    'registered' : (bool, missing_bool),\n",
    "    'viewed' : (bool, missing_bool),\n",
    "    'explored' : (bool, missing_bool),\n",
    "    'certified' : (bool, missing_bool),\n",
    "    'completed' : (bool, missing_bool),\n",
    "    'latitude' : (float, missing_float),\n",
    "    'longitude' : (float, missing_float), \n",
    "    'YoB' : (int, missing_int),\n",
    "    'grade' : (float, missing_float),\n",
    "    'passing_grade' : (float, missing_float),\n",
    "    'start_time' : ('datetime', missing_datetime),\n",
    "    'first_event' : ('datetime', missing_datetime),\n",
    "    'last_event' : ('datetime', missing_datetime),\n",
    "    'nevents' : (int, missing_int),\n",
    "    'ndays_act' : (int, missing_int),\n",
    "    'nplay_video' : (int, missing_int),\n",
    "    'nchapters' : (int, missing_int),\n",
    "    'nforum_posts' : (int, missing_int),\n",
    "    'nforum_votes' : (int, missing_int),\n",
    "    'nforum_endorsed' : (int, missing_int),\n",
    "    'nforum_threads' : (int, missing_int),\n",
    "    'nforum_comments' : (int, missing_int),\n",
    "    'nforum_pinned' : (int, missing_int),\n",
    "    'nprogcheck' : (int, missing_int),\n",
    "    'nproblem_check' : (int, missing_int),\n",
    "    'nforum_events' : (int, missing_int),\n",
    "    'is_active' : (int, missing_int),\n",
    "    'cert_created_date' : ('datetime', missing_datetime),\n",
    "    'cert_modified_date' : ('datetime', missing_datetime)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fix_types` function will be equipped to deal with missingness in the columns provided to the function. Following the guidelines from above, we will \"flag and fill\", meaning we will put in a default value like 0 and add a column indicating the a value in that field was missing. We will deal with the missingness in the string values after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "dt_format_catch = \"%Y-%m-%d %H:%M:%S.%f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goes through columns specified in the dictionary (the keys) and casts them as the \n",
    "appropriate type (the value). The dict will only contain fields that need to be \n",
    "changed from string, as everything else should be left as a string. For fields of \n",
    "datetime format, the input variables dt_format is the format provided to strptime,\n",
    "dt_format_catch is the alternative datetime format in the case dt_format caused an \n",
    "error. This function 'flags and fills', meaning it fills missing values with the \n",
    "default specified in the dictionary and adds columns to the dataframe to indicate\n",
    "the missingness of fields.\n",
    "\"\"\"\n",
    "def fix_types(df, type_dict, dt_format, dt_format_catch):\n",
    "    #the function passed to the apply on the column\n",
    "    def fix_type(s, type_value, missing_value, dt_format, dt_format_catch):\n",
    "        if pd.isnull(s) or s=='' or s==' ' or s=='none':\n",
    "            return missing_value\n",
    "        if type_value != 'datetime':\n",
    "            try:\n",
    "                return type_value(s)\n",
    "            except ValueError as v: #handles junk datapoints\n",
    "                #helps identify other shift\n",
    "                print('potential shift: '+s) #if correct, should never print\n",
    "                assert(False) #unit testing to ensure it works\n",
    "                return missing_value\n",
    "        elif type_value == 'datetime':\n",
    "            try:\n",
    "                return datetime.strptime(s, dt_format)\n",
    "            except ValueError as v:\n",
    "                return datetime.strptime(s, dt_format_catch)\n",
    "    for key, (type_value, missing_value) in type_dict.items():\n",
    "        print('Cleaning ' + str(key) + '...')\n",
    "        df[key] = df[key].apply(lambda s : fix_type(s, type_value, missing_value,\n",
    "                                                   dt_format, dt_format_catch))\n",
    "        #check if contains missing_value and add column\n",
    "        if missing_value in df[key].values:\n",
    "            df['missing_'+str(key)] = df[key]==missing_value\n",
    "    print('Finished!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written the function to help us find more shifts. For example, we have just identified that the empty string in the `completed` field is the source of a shift. We will go back and fix that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning user_id...\n",
      "Cleaning registered...\n",
      "Cleaning viewed...\n",
      "Cleaning explored...\n",
      "Cleaning certified...\n",
      "Cleaning completed...\n",
      "Cleaning latitude...\n",
      "Cleaning longitude...\n",
      "Cleaning YoB...\n",
      "Cleaning grade...\n",
      "Cleaning passing_grade...\n",
      "Cleaning start_time...\n",
      "Cleaning first_event...\n",
      "Cleaning last_event...\n",
      "Cleaning nevents...\n",
      "Cleaning ndays_act...\n",
      "Cleaning nplay_video...\n",
      "Cleaning nchapters...\n",
      "Cleaning nforum_posts...\n",
      "Cleaning nforum_votes...\n",
      "Cleaning nforum_endorsed...\n",
      "Cleaning nforum_threads...\n",
      "Cleaning nforum_comments...\n",
      "Cleaning nforum_pinned...\n",
      "Cleaning nprogcheck...\n",
      "Cleaning nproblem_check...\n",
      "Cleaning nforum_events...\n",
      "Cleaning is_active...\n",
      "Cleaning cert_created_date...\n",
      "Cleaning cert_modified_date...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "df_clean = fix_types(df_clean, type_dict, dt_format, dt_format_catch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have dealt with missingness in the non-string types, we will handle the string types. The guidelines recommend filling in missing categoricals (in our case all of the strings) with \"missing\". So we shall do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_list=['',' ']\n",
    "#df_clean = df_clean.replace(missing_list, 'missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas replace is incredibly slow. So we will write are own function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get columns to replace\n",
    "str_cols = list(set(df_clean.columns) - set(type_dict.keys()))\n",
    "str_cols = [s for s in str_cols if not s.startswith('missing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fills in missing values identified by the missing_list with the proper missing_value.\n",
    "Pandas fillna handles the other missing value identifers like NaN and None.\n",
    "\"\"\"\n",
    "def fix_types_strings(df, cols, missing_list=['',' '], missing_value='missing'):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].map(lambda s: missing_value if s in missing_list else s)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = fix_types_strings(df_clean, str_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have cleaned and dealt with missingness in the fields that are numerical boolean, and datetime, and properly flagged them. Now we are finished dealing with missingness and fixing the datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ip(s):\n",
    "    return (len(s.split('.'))==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_types(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Corrupt Lines and Discussing Duplicates (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first section, we discussed rows with an extra field, which threw off the importation of the dataset, and then discussed how removing duplicates affected those fields. In this section, we investigate corruptness that involves contradictoriness in the values of the dataset. I believe this is the most salient definition of corruptness as the rows are fully fleshed out, but the analysis that may come from them could be faulty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about how values in a row could contradict eachother. For one, if a student has completed the course then they also must have viewed the course. Therefore if `completed` is True and `viewed` is False we can reasonably assume something is wrong, so we will flag it. Our flagging will be in a new column we create `corrupt`. We will have to make sure that missingness is accounted for - meaning if `viewed` was actually missing, it would be default filled in with False, which would be a sign of contradiction. But we should not let missingness indicate corruption, so we will need to check the missing columns to appropriately handle these cases. Another form of contradiction can occur with `completed` and the relationship between `grade` and `passing_grade`. If `grade` < `passing_grade` and `completed` is True, than that would be a contradiction as the list of variables describes that \"grade >=\tpassing_grade\" for `completed` to be True. We will not examine potential corrupt relationships with `explored` as a student can likely pass without looking through half the course's chapters. Another potential source for corruption involves incorrect locations. For example, if someone was from New York state and the `countryLabel` is United Kingdom. We will not check for this type of corruption as it is out of the scope of this data cleaning, but we recognize the potential for problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add corruption field\n",
    "df_clean['corrupt'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean.loc[(df_clean['completed']==True) & (df_clean['viewed']==False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no circumstaces where someone has completed a course without viewing. This is good as it means the dataset is correct with respect to these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603260"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean.loc[(df_clean['completed']==True) & \n",
    "                        (df_clean['grade']<df_clean['passing_grade'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats a high number. But we need to check that `missing_grade` is False as we do not want to let missingness to be the indicator of corruptness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28041 corrupt rows (4.24% of dataset)\n"
     ]
    }
   ],
   "source": [
    "ncorrupt = len(df_clean.loc[(df_clean['completed']==True) & \n",
    "                        (df_clean['grade']<df_clean['passing_grade']) &\n",
    "                       (df_clean['missing_grade']==False)])\n",
    "print (str(ncorrupt) + \" corrupt rows (\"+str(round(float(ncorrupt)*100/len(df_clean),2))+\n",
    "                                             \"% of dataset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is far more believable. It would be worrisome to have contradictions in most of the rows. We will flag these rows now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[(df_clean['completed']==True) & \n",
    "                        (df_clean['grade']<df_clean['passing_grade']) &\n",
    "                       (df_clean['missing_grade']==False), ['corrupt']] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-551-4892df1dd753>:1: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(df_clean[df_clean['corrupt']==True])==ncorrupt, \"Corruption flagging error.\")\n"
     ]
    }
   ],
   "source": [
    "assert(len(df_clean[df_clean['corrupt']==True])==ncorrupt, \"Corruption flagging error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
